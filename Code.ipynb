{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified LeNet Network \n",
    "## Classification Of Cheetah, Jaguar and Leopard on the basis of LeNet-5 Network Architecture\n",
    "\n",
    "#### **INPUT Layer**\n",
    "The first is the data INPUT layer. The size of the input image is uniformly normalized to 64 * 64.\n",
    "\n",
    "#### **C1 layer-convolutional layer**\n",
    ">**Input picture**: 64 * 64\n",
    "\n",
    ">**Convolution kernel size**: 5 * 5\n",
    "\n",
    ">**Convolution kernel types**: 6\n",
    "\n",
    ">**Output featuremap size**: 60 * 60 (64-5 + 1) = 60\n",
    "\n",
    ">**Number of neurons**: 60 * 60 * 6\n",
    "\n",
    ">**Trainable parameters**: (5 * 5 + 1) * 6 (5 * 5 = 25 unit parameters and one bias parameter per filter, a total of 6 filters)\n",
    "\n",
    ">**Number of connections**: (5 * 5 + 1) * 6 * 60 * 60 = 5,61,600\n",
    "\n",
    "#### **S2 layer-pooling layer (downsampling layer)**\n",
    "\n",
    ">**Input**: 60 * 60\n",
    "\n",
    ">**Sampling area**: 3 * 3\n",
    "\n",
    ">**Sampling method**: 4 inputs are added, multiplied by a trainable parameter, plus a trainable offset. Results via relu\n",
    "\n",
    ">**Sampling type**: 6\n",
    "\n",
    ">**Output featureMap size**: 30 * 30 (60/2)\n",
    "\n",
    ">**Number of neurons**: 30 * 30 * 6\n",
    "\n",
    ">**Trainable parameters**: 3 * 6 (the weight of the sum + the offset)\n",
    "\n",
    ">**Number of connections**: (3 * 3 + 1) * 6 * 30 * 30\n",
    "\n",
    "\n",
    "#### **C3 layer-convolutional layer**\n",
    "\n",
    ">**Input**: all 6 or several feature map combinations in S2\n",
    "\n",
    ">**Convolution kernel size**: 3 * 3\n",
    "\n",
    ">**Convolution kernel type**: 16\n",
    "\n",
    ">**Output featureMap size**: 28 * 28 (30-3 + 1) = 28\n",
    "\n",
    "\n",
    "#### **S4 layer-pooling layer (downsampling layer)**\n",
    "\n",
    ">**Input**: 28 * 28\n",
    "\n",
    ">**Sampling area**: 2 * 2\n",
    "\n",
    ">**Sampling type**: 16\n",
    "\n",
    ">**Output featureMap size**: 14 * 15 (28/2)\n",
    "\n",
    "#### **F6 layer-fully connected layer**\n",
    "\n",
    ">**Input**: c3 120-dimensional vector\n",
    "\n",
    ">**Calculation method**: calculate the dot product between the input vector and the weight vector, plus an offset, and the result is output through the sigmoid function.\n",
    "\n",
    ">**Trainable parameters**: 84 * (120 + 1) = 10164\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#Select 6 Convolution of size 3*3 , Input size of image is 32*32*3, it is a RGB image\n",
    "classifier.add(Conv2D(6, kernel_size=(5,5), activation='relu', input_shape=(64,64, 3)))\n",
    "#The output of the Convolution layer is 60*60*6 \n",
    "#Trainable parameters is (5 * 5 + 1) * 6= 156; \n",
    "#(5 * 5 = 25 unit parameters and one bias parameter per filter, a total of 6 filters)\n",
    "\n",
    "classifier.add( MaxPooling2D( pool_size=(3,3)))\n",
    "#The output of the Maximum Pooling layer is 30*30*6\n",
    "\n",
    "#The input matrix size of this layer is 30 * 30 * 6, the filter size used is 3 * 3, and the depth is 16. This layer does not use all 0 padding, and the step size is 1.\n",
    "# The output matrix size of this layer is 28 * 28 * 16.\n",
    "classifier.add(Conv2D(16, kernel_size=(3,3), activation='relu'))\n",
    "#The output of the Second Convolution layer is (30-3+1)=28\n",
    "classifier.add( MaxPooling2D( pool_size=(2,2)))\n",
    "#The output of the Maximum Pooling layer is 14*14*16\n",
    "classifier.add(Conv2D(16, kernel_size=(5,5), activation='relu'))\n",
    "#The output of the Second Convolution layer is (14-5+1)=10; 10*10*16\n",
    "classifier.add( MaxPooling2D( pool_size=(2,2)))\n",
    "#The output of the Maximum Pooling layer is 5*5*16\n",
    "# The input matrix size of this layer is 5 * 5 * 16. This layer is called a convolution layer in the LeNet-5 paper, but because the size of the filter is 5 * 5, #\n",
    "# So it is not different from the fully connected layer. If the nodes in the 5 * 5 * 16 matrix are pulled into a vector, then this layer is the same as the fully connected layer.\n",
    "# The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(120, activation='relu'))\n",
    "\n",
    "# The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n",
    "classifier.add(Dense(84, activation='relu'))\n",
    "\n",
    "classifier.add(Dense(3, activation='softmax'))\n",
    "classifier.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 images belonging to 3 classes.\n",
      "Found 10 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "test_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "training_set = train_data.flow_from_directory(\"C:/Users/Prateek's PC/Desktop/dataset/train\",\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "test_set = test_data.flow_from_directory(\"C:/Users/Prateek's PC/Desktop/dataset/test\",\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 19s 2s/step - loss: 1.0678 - accuracy: 0.4118 - val_loss: 1.0238 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.9950 - accuracy: 0.4882 - val_loss: 0.8903 - val_accuracy: 0.6000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.8496 - accuracy: 0.7294 - val_loss: 0.6485 - val_accuracy: 0.8700\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.6035 - accuracy: 0.8176 - val_loss: 0.4571 - val_accuracy: 0.8900\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.4128 - accuracy: 0.8588 - val_loss: 0.3094 - val_accuracy: 0.9600\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.2570 - accuracy: 0.9412 - val_loss: 0.1792 - val_accuracy: 0.8900\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.1341 - accuracy: 0.9824 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0910 - accuracy: 0.9765 - val_loss: 0.0676 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a9a1f4ff88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 10,\n",
    "                         epochs = 10,\n",
    "                         validation_data = test_set,    \n",
    "                         validation_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]]\n",
      "leopard\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making new predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(\"C:/Users/Prateek's PC/Desktop/dataset/t1.jfif\", target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'cheetah'\n",
    "    print(prediction)\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 'jaguar'\n",
    "    print(prediction)\n",
    "    \n",
    "else:\n",
    "    prediction = 'leopard'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
